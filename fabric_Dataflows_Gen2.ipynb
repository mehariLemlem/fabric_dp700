{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15708d76",
   "metadata": {},
   "source": [
    "In Microsoft Fabric, Dataflows (Gen2) connect to various data sources and perform transformations in [Power Query Online](https://learn.microsoft.com/en-us/power-query/power-query-ui). They can then be used in Data Pipelines to ingest data into a lakehouse or other analytical store, or to define a dataset for a Power BI report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6217ff90",
   "metadata": {},
   "source": [
    "## Prerequisites ##\n",
    "- Access to a Microsoft Fabric enabled tenant\n",
    "- At least [**Contributor**](https://learn.microsoft.com/en-us/fabric/fundamentals/roles-workspaces) access to a workspace\n",
    "- The workspace must be assigned to a [**Fabric capacity**](https://learn.microsoft.com/en-us/fabric/enterprise/licenses)\n",
    "    - (hint: Workspace â†’ Workspace settings â†’ License info â†’ edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e5e4e",
   "metadata": {},
   "source": [
    "## Create Workspace ##\n",
    "1) Navigate to the [Microsoft Fabric home page](https://app.fabric.microsoft.com/home?experience=fabric)\n",
    "2) In the menu bar on the left, select Workspaces (the icon looks similar to ðŸ—‡)\n",
    "3) Create a new workspace with a name of your choice, selecting a licensing mode that includes Fabric capacity (Trial, Premium, or Fabric)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d42ce",
   "metadata": {},
   "source": [
    "## Create Lakehouse ##\n",
    "1) Inside the workspace, click **+ New**.\n",
    "2) Select Lakehouse under the **Data Engineering** section.\n",
    "3) Click **Create**.\n",
    "\n",
    "Once created, you Lakehouse will have:\n",
    "- Tables folder â†’ structured Delta tables\n",
    "- Files folder â†’ unstructured / raw data\n",
    "- Built-in SQL endpoint for querying\n",
    "- Auto-created Power BI semantic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078ae98",
   "metadata": {},
   "source": [
    "## [Ingest data to your lakehouse using Dataflow (Gen2)](https://learn.microsoft.com/en-us/fabric/data-factory/create-first-dataflow-gen2) ##\n",
    "Define a **dataflow** that encapsulates an extract, transform, and load (ETL) process\n",
    "1) In the home page for your lakehouse, select **Get data â†’ New Dataflow Gen2**.\n",
    "    - In a while **Power Query editor** for your new dataflow opens\n",
    "2) Select **Import from a Text/CSV file**, and create a new **data source** with the following settings:\n",
    "- **Link to file**: Selected\n",
    "- **File path or URL**: https://raw.githubusercontent.com/MicrosoftLearning/dp-data/main/orders.csv\n",
    "- **Connection**: Create new connection\n",
    "- **Connection name**: Specify a unique name\n",
    "- **data gateway**: (none)\n",
    "- **Authentication kind**: Anonymous\n",
    "3) Transform the data\n",
    "- Add column â†’ Custom column\n",
    "    - **New column name:** MonthNo\n",
    "    - **Data type:** Whole Number\n",
    "    - **Formula:** Date.Month([OrderDate]) \n",
    "4) Add **data destination**\n",
    "- Home â†’ Query â†’ Add data destination\n",
    "- Disable **Use automatic settings** option\n",
    "- Select **Append** and then **Save settings**\n",
    "- **View** â†’ **Diagram view**\n",
    "- **Home** â†’ **Save & run**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e14ec3",
   "metadata": {},
   "source": [
    "## Add a dataflow to a pipeline ##\n",
    "You can include a dataflow as an **activity** in a pipeline. Pipelines are used to **orchestrate** data ingestion and processing activities, enabling you to combine dataflows with other kinds of operation in a single, **scheduled** process. Pipelines can be created in a few different experiences, including **Data Factory experience**.\n",
    "1) Fabric-enabled workspace â†’ **+ New item** â†’ Data pipeline â†’ Create\n",
    "2) Pipeline activity â†’ Dataflow\n",
    "3) Settings â†’ from Dataflow drop-down list (select the data flow you created previously)\n",
    "4) Home â†’ ðŸ–« (Save) icon â†’ â–· Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c88f4",
   "metadata": {},
   "source": [
    "**Tip:** \n",
    "- In Power BI Desktop, you can connect directly to the data transformations done with your dataflow by using the Power BI dataflows (Legacy) connector. You can also make additional transformations, publish as a new dataset, and distribute with intended audience for specialized datasets.\n",
    "- You can split dataflows by data slices (like region or year), and once you have a central trusted dataflow, analysts can build smaller, customized models from it without re-creating the data from scratch.\n",
    "- In Fabric, a global dataflow provides standardized enterprise data, and horizontal partitioning lets us split it by region, year, or business unit. Analysts then build specialized semantic models from the global dataflow instead of pulling from raw systems, which improves performance, governance, and consistency.\n",
    "- Dataflows Gen2 simplifies ingestion and transformation in Fabric by writing curated data directly to OneLake and enabling reuse across teams. It works best for batch-based, low-code ETL and semantic model preparation, but itâ€™s not suitable for real-time processing, very large-scale transformations, or complex DevOps-driven workloads."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
